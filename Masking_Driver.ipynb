{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datadiscovery import *\n",
    "import mysql.connector as mysqlConnector\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection variables to mysql DB where we have the requests from user and required metadata tables supporting this utility\n",
    "localcon = mysqlConnector.connect(host='VBSE1192P-01', user='root',passwd='****')\n",
    "engine = create_engine ('mysql+pymysql://root:****@BSE1192P-01:3306/tdm_trg', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Request ID for the request submitted by user from front end (For testing this utility, included this as input from user here)\n",
    "req_id=input(\"Please enter a req id:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading user request from table tbl_data_rqt_hd which contains source table names that has to be masked along with source and target connection names\n",
    "Request_dtls_df=pd.read_sql(\"select request_tbl_dt,sr_connection_name,tr_connection_name from tdm_trg.tbl_data_rqt_hd where Request_ID=\"+req_id, localcon\n",
    "src_connection_name=Request_dtls_df[0,1]\n",
    "trg_connection_name=Request_dtls_df[0,2]                           \n",
    "#reading source's connection details from metadata table-tbl_connection using connection name fetched from the user request\n",
    "#tbl_connection - this table will have all the required connection information predefined which will be maintained by tool administrator\n",
    "source_con_df=pd.read_sql(\"select data_base, host_name, port, user_id, password, db_name from tdm_trg.tbl_connection where connection_id={}\".format(soure_table_dtls_df[0,1]),localcon)\n",
    "\n",
    "#creating source connection variable\n",
    "server = source_con_df. iloc[0,1]\n",
    "database = source_con_df. iloc[0,5]\n",
    "username = source_con_df. iloc[0,3)\n",
    "password = source_con_df. iloc[0,4]\n",
    "\n",
    "if re.search(src_connection_name,'MySQL'):\n",
    "    sourcecon=mysqlConnector.connect(host=server, user=username,passwd= password,database=database)\n",
    "elif re.search(src_connection_name,'MSSQL'):\n",
    "    sourcecon=pyodbc.connect('DRIVER={SQL Server}; SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)                                                     \n",
    "\n",
    "#Triggering data discovery which identifies the sensitive fields in the source file/table                 \n",
    "if re.search(Request_dtls_df.request_tbl_dt,'.csv')\n",
    "    fileDataDiscovery(Request_dtls_df)\n",
    "    fileMaskingDriver()\n",
    "else\n",
    "    tableDataDiscovery(Request_dtls_df,sourcecon)\n",
    "    tableMaskingDriver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the request ID for user's request, gathering the source schema,table/file and sensitive details information from Data Discovery table in mySQL\n",
    "data_discovery=pd.read_sql_query(\"SELECT distinct tbl_schema, tbl_name_dt, Sensitive_Fields \\\n",
    "FROM tdm_trg. tbl_data_discovery_hd where Request_id={}\".format(req_id), localcon); \n",
    "data_discovery['Sensitive_Fields']=data_discovery[ 'Sensitive_Fields'].map(lambda x:x.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileMaskingDriver:\n",
    "    dicts=list(data_discovery.tbl_name_dt.unique())\n",
    "    tablename=dicts[0] \n",
    "    dicts=[i.replace('.','_') for i in dicts]\n",
    "    temp=dict()\n",
    "    for a in dicts: \n",
    "        temp[\"{}\".Format(a)]=dict()\n",
    "    #Reading file into dataframe from user request in tbl_data_rqt_hd table     \n",
    "    file1=pd.read_sql(\"select template from tdm trg.tbl_data_rqt_hd where Request_ID=\"+req_id, localcon) \n",
    "    folderpath=pd.read_sql(\"SELECT folder_name FROM tdm_trg.tbl_folder_settings\",localcon) \n",
    "    with open(folderpath.iloc[0,0]+tablename, 'wb') as file:\n",
    "        file.write(file1.iloc[0,0]) \n",
    "    with open(folderpath.iloc[0,0]+tablename, 'r+') as file:\n",
    "        lines= file.readlines()\n",
    "        lines=[line for line in lines if line.strip()] \n",
    "    with open(folderpath.iloc[0,0]+tablename, 'w') as file:\n",
    "        [file.write(line) for line in lines ]\n",
    "    \n",
    "    for index in range(data_discovery.shape[0]): \n",
    "        schema=data discovery.iloc[index,0]\n",
    "        tablename=data_discovery.iloc[index,1] \n",
    "        df=pd.read_csv(folderpath.iloc[0,0]+tablename)\n",
    "        df.columns=[i.strip() for i in df.columns]\n",
    "        df.columns=[i.lower() for i in df.columns] \n",
    "        tablename=tablename.replace('.','_')\n",
    "        columnname=data_discovery.iloc[index,2] \n",
    "        \n",
    "        Name=pd.read_sql(\"select Lookup_Field_Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd=\"Name\", localcon)\n",
    "        Name=list(Name.iloc[:,0].map(lambda x: x.lower()))\n",
    "\n",
    "        Address=pd.read_sql(\"select Lookup_Field Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd='Address\", localcon) \n",
    "        Address=list(Address.iloc[:,0).map(lambda x: x.lower()))\n",
    "\n",
    "        Birth_date-pd.read_sql(\"select Lookup_ Field Names from tdm_trg. tbl_lookup where Lookup_Feild_Hd='Birth_date\", localcon) \n",
    "        Birth_date=list(Birth_date.iloc[:,0).map(lambda x:x.lower())) \n",
    "\n",
    "        Email=pd.read_sql(\"select Lookup_Field_Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd=\"Email\"\", localcon) \n",
    "        Email=list(Email.iloc[:,0].map(lambda x: x.lower()))\n",
    "\n",
    "        Age=pd.read_sql(\"select Lookup Field Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd=\"Age\", localcon) \n",
    "        Age=list (Age.iloc[:,0].map(lambda x: x.lower()))\n",
    "        dob1=\"\"\n",
    "        namel=\"\"\n",
    "        if columnname in Name : \n",
    "            namel=columnname\n",
    "            temp[tablename][columnname] =f.name(df,columnname)\n",
    "        elif columnname in Address: \n",
    "            temp[tablename][columnname]=f.address(df,columnname) \n",
    "        elif columnname in Birth_date:\n",
    "            dob1=columnname\n",
    "            temp[tablename][columnname] =f.dob(df,columnname) \n",
    "        elif columnname in Age:\n",
    "            if dob1 in temp[tablename].keys(): \n",
    "                temp[tablename][columnname]=f.age(temp[tablename][dob1]) \n",
    "        elif columnname in Email:\n",
    "            if name1 in temp[tablename].keys():\n",
    "                temp[tablename][columnname]=f.email(temp[tablename][name1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableMaskingDriver():\n",
    "    dicts=list(data_discovery.tbl_name_dt.unique())\n",
    "    temp=dict()\n",
    "    for a in dicts: \n",
    "        temp[\"{}\".Format(a)]=dict()\n",
    "        \n",
    "    for index in range(data_discovery.shape[0]): \n",
    "        schema=data discovery.iloc[index,0]\n",
    "        tablename=data_discovery.iloc[index,1] \n",
    "        columnname=data_discovery.iloc[index,2]\n",
    "        \n",
    "        tablename=tablename.lower()\n",
    "        columnname=columnname.lower()\n",
    "        \n",
    "        Name=pd.read_sql(\"select Lookup_Field_Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd=\"Name\", localcon)\n",
    "        Name=list(Name.iloc[:,0].map(lambda x: x.lower()))\n",
    "                     \n",
    "        Address=pd.read_sql(\"select Lookup_Field Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd='Address\", localcon) \n",
    "        Address=list(Address.iloc[:,0].map(lambda x: x.lower()))\n",
    "                              \n",
    "        Birth_date=pd.read_sql(\"select Lookup_ Field Names from tdm_trg. tbl_lookup where Lookup_Feild_Hd='Birth_date\", localcon) \n",
    "        Birth_date=list(Birth_date.iloc[:,0].map(lambda x:x.lower())) \n",
    "    \n",
    "        Email=pd.read_sql(\"select Lookup_Field_Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd=\"Email\"\", localcon) \n",
    "        Email=list(Email.iloc[:,0].map(lambda x: x.lower()))\n",
    "                                    \n",
    "        Age=pd.read_sql(\"select Lookup Field Names from tdm_trg.tbl_lookup where Lookup_Feild_Hd=\"Age\", localcon) \n",
    "        Age=list (Age.iloc[:,0].map(lambda x: x.lower()))\n",
    "                        \n",
    "      \n",
    "    if columnname in Name : \n",
    "        temp[tablename][columnname] =t.name(schema,tablename,columnname,sourcecon)\n",
    "    elif columnname in Address: \n",
    "        temp[tablename][columnname]=t.address(schema,tablename,columnname,sourcecon) \n",
    "    elif columnname in Birth_date:\n",
    "        temp[tablename][columnname] =t.dob(schema,tablename,columnname,sourcecon) \n",
    "    elif columnname in Age:\n",
    "            temp[tablename][columnname]=t.age(schema,tablename,columnname,temp[tablename][\"dob\"]) \n",
    "    elif columnname in Email:\n",
    "            temp[tablename][columnname]=t.email(temp[tablename][\"name\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToBinaryData(filename):\n",
    "    #convert digital data to binary format\n",
    "    with open(filename,'rb') as file:\n",
    "        binaryData=file.read()\n",
    "    return binaryData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the masked data as attachment in request table -tbl_data_rqt_details as blob\n",
    "#Also creating the masked table in mySQL DB itself. \n",
    "\n",
    "for k,v in temp.items():\n",
    "    src_table=df\n",
    "    h=p;d.DataFrame(temp[k])\n",
    "    for i in list(src_table.columns):\n",
    "        if i not in list(h.columns):\n",
    "            h=pd.concat([h,src_table[i]],axis=1)\n",
    "    # creating the masked table in mySQL DB -- This functionality can be extended to other target DBs as well . \n",
    "    h.to_sql(name=k+\"_mockup\",con=engine,index=False,if_exists='replace')\n",
    "    folderpath=pd.read_sql(\"select folder_name from tdm_trg.tbl_folder_settings\",localcon)\n",
    "    h.to_csv(folderpath.iloc[0,0]+k+\"_mockup.csv\",index=False)\n",
    "    file=convertToBinaryData(folderpath.iloc[0,0]+k+\"_mockup.csv\")\n",
    "    k=k.replace('_','mockup.')\n",
    "    query1=\"insert into tdm_trg.tbl_data_rqt_details (Request_ID,FirstName,Attachment) values (%s,%s,%s)\"\n",
    "    args1=(req_id,k,file)\n",
    "    cursor=localcon.cursor()\n",
    "    cursor.execute(query1,args1)\n",
    "    \n",
    "localcon.commit()\n",
    "cursor.close()\n",
    "localcon.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
