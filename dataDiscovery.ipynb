{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as mysqlConnector \n",
    "from datetime import datetime \n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localcon = mysqlConnector.connect(host='VBSE1192P-01', user='root',passwd='****')\n",
    "engine = create_engine ('mysql+pymysql://root:****@BSE1192P-01:3306/tdm_trg', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableDataDiscovery(Request_dtls_df,sourcecon):\n",
    "\n",
    "cursor=Sourcecon.cursor()\n",
    "\n",
    "#Reading pre defined sensitive fields from metadata table - tbl_lookup and storing in a list\n",
    "Lookup_table_Columns_df=pd.read_sql(\"select lookup_field_names from tdm_trg.tbl_lookup\", localcon)\n",
    "Lookup_table_Columns_list=list(Lookup_table_Columns_df.lookup_field_names)\n",
    "\n",
    "#reading the entire row of request from tbl_data_rqt_hd table for fetching other details required for data discovery \n",
    "File_request_df=pd.read_sql(\"select * from tdm trg.tbl_data_rqt_hd where Request ID=\"+req_id,localcon)\n",
    "\n",
    "#Fetching columns from each of the source tables mentioned in the request and finding sensitive fields by comparing with lookup-data from above list\n",
    "#Also inserting these sensitive fields for each of the source tables into data discovery metadata table tbl_data_discovery_hd in mySQL\n",
    "for i in source_tables_list:\n",
    "    i+\"_column_list\"=list((pd.read_sql(\"select * from \"+i,Sourcecon)).columns)\n",
    "    i+\"_column_list\".lower()\n",
    "    i+\"_Sensitive_fields\"=list(set(i+\"_column_list\")&set(map(str.lower,Lookup_table_Columns_list)))\n",
    "    i+\"_Data_Discovery_df\"=pd.DataFrame ({'Requestid':File_request_df.iloc[0,0], 'tbl_schema':File_request_df.iloc[0,3],'tbl_name_dt':File_request_df.iloc[0,4], 'Sensitive_Fields':i+\"_Sensitive_fields\", 'discovery_DT': now.strftime('%Y-%m-%d')})\n",
    "    sql=\"INSERT INTO tdm_trg.tbl_data_discovery_hd(Request_id, tbl_schema, tbl_name_dt, Sensitive_Fields, discovery_DT) VALUES(%s,%s,%s,%s,%s)\"\n",
    "    for j,row in i+\"_Data_Discovery_df\".iterrows ():\n",
    "        cursor.execute(sql, tuple(row)) \n",
    "        localcon.comit()\n",
    "\n",
    "cursor.close() \n",
    "localcon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileDataDiscovery(Request_dtls_df):\n",
    "    cursor=Sourcecon.cursor()\n",
    "    #if the request is for file masking , source file is read into the folder path specified in folder metadata table\n",
    "    file1=pd.read_sql(\"select template from tdm_trg.tbl_data_rqt_hd where Request_ID=\"+req_id, localcon)\n",
    "    folderpath=pd.read_sql(\"SELECT folder_name FROM tdm_trg.tbl_folder_settings\",localcon) \n",
    "    with open(folderpath.iloc[0,0]+str(req_id)+\".csv\", 'w') as file: \n",
    "        file.write(file1.iloc [0,0])\n",
    "    with open(folderpath.iloc[0,0]+str(req_id)+\".csv\", 'r+') as file: \n",
    "        lines= file.readlines()\n",
    "        lines=[line for line in lines if line.strip()] \n",
    "    with open(folderpath. iloc[0,0]+str(req_id)+\".csv\", 'w') as file: \n",
    "        [file.write(line) for line in lines]\n",
    "    \n",
    "    File_request_df=pd.read_sql(\"select * from tdm trg.tbl_data_rqt_hd where Request ID=\"+req_id,localcon)\n",
    "    df_csv=pd.read_csv(folderpath.iloc[0,0]+str(req_id)+\".csv\")\n",
    "    CSV_Column_list=list(df_csv.columns)\n",
    "    Lookup_table_Columns_df=pd.read_sql(\"select lookup_field_names from tdm_trg.tbl_lookup\", localcon)\n",
    "    Lookup_table_Columns_list=list(Lookup_table_Columns_df.lookup_field_names)\n",
    "    Sensitive_fields_CSV=set(CSV_Column_list)&set(map(str.lower,Lookup_table_Columns_list))\n",
    "    Sensitive_fields_CSV=list(Sensitive_fields_CSV)\n",
    "    \n",
    "    Data_Discovery_df=pd.DataFrame ({'Requestid':File_request_df.iloc[0,0], 'tbl_schema':File_request_df.iloc[0,3],'tbl_name_dt':File_request_df.iloc[0,4], 'Sensitive_Fields':Sensitive_fields_CSV, 'discovery_DT': now.strftime('%Y-%m-%d')})\n",
    "    \n",
    "    cursor=localcon.cursor()\n",
    "    sql=\"INSERT INTO tdm_trg.tbl_data_discovery_hd(Request_id, tbl_schema, tbl_name_dt, Sensitive_Fields, discovery_DT) VALUES(%s,%s,%s,%s,%s)\"\n",
    "    for i,row in Data_Discovery_df.iterrows ():\n",
    "        cursor.execute(sql, tuple(row)) \n",
    "        localcon.comit()\n",
    "    cursor.close() \n",
    "    localcon.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
